{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download All The Images\n",
    "\n",
    "You need a SpaceWarps installation plus pickles in order to be able to do the first step of reducing to a catalog. Sorry.\n",
    "\n",
    "I skipped stage1 tests that were still undecided. I think those go into stage 2. This saves a lot of images probably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Incorporate skill into outlier_clusters_dbscan\n",
    "- add check_make for the different directories\n",
    "- add object detection for all objects in field as well as click locations\n",
    "- paths for catalogs etc are now messed up\n",
    "\n",
    "- put in the real lenses\n",
    "\n",
    "- remake cutouts using just sims and duds from stage1 as well as knownlens, and everything from stage2\n",
    "- next time when making the clusters make the filenames and alpha statuses too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here you specify some paths for files!\n",
    "project_path = '/Volumes/Seagate/cs231n/'\n",
    "# pickles path\n",
    "base_collection_path = project_path + 'swap_pickles/09.02.15/'\n",
    "# catalog path\n",
    "annotated_catalog_path = project_path + 'catalog/annotated_catalog.csv'\n",
    "# repeat without annotations\n",
    "unannotated_catalog_path = project_path + 'catalog/unannotated_catalog.csv'\n",
    "# cluster catalog path\n",
    "cluster_catalog_path = project_path + 'catalog/cluster_catalog.csv'\n",
    "# images path\n",
    "images_path = project_path + 'images/fields/'\n",
    "# cutouts path\n",
    "cutouts_path = project_path + 'images/cutouts/'\n",
    "# cache dir for clustering\n",
    "cachedir = '../.cache'\n",
    "# knownlens catalog\n",
    "knownlens_path = project_path + 'knownlens/knownlens.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here are some other config parameters\n",
    "categories = ['ID', 'ZooID', 'location', 'mean_probability', 'category', 'kind', 'flavor', 'state', 'status', 'truth',\n",
    "              'stage']\n",
    "# annotation_categories = ['At_X', 'At_Y', 'ItWas', 'Name', 'PD', 'PL']\n",
    "annotation_categories = ['At_X', 'At_Y', 'PD', 'PL']\n",
    "cluster_catalog_labels = ['cluster_label', 'cluster_ID', 'x', 'y', 'num_markers', 'skill_sum', 'dist_within',\n",
    "                          'cutoutname', 'fieldname']\n",
    "\n",
    "eps = int(96 * 0.5)\n",
    "min_samples = 2\n",
    "stamp_size = eps * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log2, ndarray\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def outlier_clusters_dbscan(x, y, skill=None, memory=None,\n",
    "                            eps=25, min_samples=5,\n",
    "                            convert_outliers=True):\n",
    "    \"\"\"\n",
    "    DBSCAN parameters\n",
    "    eps : float, optional\n",
    "        The maximum distance between two samples for them to be considered\n",
    "        as in the same neighborhood.\n",
    "    min_samples : int, optional\n",
    "        The number of samples in a neighborhood for a point to be considered\n",
    "        as a core point.\n",
    "        \n",
    "    convert_outliers : binary, optional\n",
    "        DBSCAN assigns outliers a cluster label -1. This says take each -1 and give it a unique positive value\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: incorporate skill\n",
    "    data = np.vstack((x, y)).T\n",
    "\n",
    "    if len(data) == 0:\n",
    "        # uh.\n",
    "        print('clustering: NO cluster members!')\n",
    "        cluster_centers = np.array([[-1, -1]])\n",
    "        cluster_labels = []\n",
    "        labels = []\n",
    "        n_clusters = 0\n",
    "        dist_within = np.array([])\n",
    "\n",
    "    elif len(data) == 1:\n",
    "        #print('clustering: only 1 data point!')\n",
    "        cluster_centers = data\n",
    "        cluster_labels = [0]\n",
    "        labels = np.array([0])\n",
    "        n_clusters = 1\n",
    "        dist_within = np.array([0])\n",
    "\n",
    "    else:\n",
    "\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        db = clusterer.fit(data)\n",
    "        labels = db.labels_\n",
    "        n_clusters = len(set(labels))\n",
    "        cluster_labels = list(set(labels))\n",
    "        if convert_outliers:\n",
    "            # now step through all the labels and set the -1s each to a new unique label\n",
    "            label_max = np.max((max(cluster_labels) + 1, 101))\n",
    "            for label_i, label in enumerate(labels):\n",
    "                if label == -1:\n",
    "                    labels[label_i] = label_max\n",
    "                    label_max += 1\n",
    "            cluster_labels = list(set(labels))\n",
    "        # cludgey\n",
    "        cluster_centers = np.array([np.mean(data[labels == i], axis=0)\n",
    "                                    for i in cluster_labels])\n",
    "        \n",
    "\n",
    "    # print n_clusters\n",
    "    # print labels\n",
    "\n",
    "    # cludgey\n",
    "    dist_within_final = np.array([np.max(pairwise_distances(\n",
    "            data[labels == i])) for i in cluster_labels])\n",
    "\n",
    "    return cluster_centers, cluster_labels, labels, n_clusters, dist_within_final\n",
    "\n",
    "outlier_clusters = outlier_clusters_dbscan\n",
    "\n",
    "def shannon(x):\n",
    "\n",
    "    if isinstance(x, ndarray) == False:\n",
    "\n",
    "        if x>0:\n",
    "            res = x*log2(x)\n",
    "        else:\n",
    "            res = 0.0\n",
    "    \n",
    "    else:\n",
    "        x[x == 0] = 1.0\n",
    "        res = x*log2(x)\n",
    "\n",
    "    return res\n",
    "\n",
    "def expectedInformationGain(p0, M_ll, M_nn):\n",
    "\n",
    "    p1 = 1-p0\n",
    "\n",
    "    I =   p0 * (shannon(M_ll) + shannon(1-M_ll)) \\\n",
    "        + p1 * (shannon(M_nn) + shannon(1-M_nn)) \\\n",
    "        - shannon(M_ll*p0 + (1-M_nn)*p1) \\\n",
    "        - shannon((1-M_ll)*p0 + M_nn*p1)\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imsave\n",
    "from os import path\n",
    "from urllib import FancyURLopener\n",
    "\n",
    "# the fancy way of scraping images from the web; you gotta pretend you are a browser\n",
    "class MyOpener(FancyURLopener):\n",
    "    version = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'\n",
    "myopener = MyOpener()\n",
    "\n",
    "def get_online_png(url, outname):\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    # download file if we don't already have it\n",
    "    if not path.exists(outname):\n",
    "        F = myopener.retrieve(url, outname)\n",
    "    else:\n",
    "        # TODO: this is glitched?!\n",
    "        F = [outname]\n",
    "    I = imread(F[0]) * 1. / 255\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce pickles to catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A catalog of stage1 and stage2 field objects with:\n",
    "    - ID (for later retrieval)\n",
    "    - probability from users\n",
    "I could probably reduce the following into one or two parameters\n",
    "    - category\n",
    "    - kind\n",
    "    - flavor\n",
    "    - state\n",
    "    - status\n",
    "    - truth\n",
    "When I make the cutouts I will also need:\n",
    "    - locations of clicks and associated skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import swap\n",
    "stages = range(1, 3)\n",
    "\n",
    "\n",
    "# TODO: incorporate knownlens info.\n",
    "catalog = []\n",
    "for stage in stages:\n",
    "    print(stage)\n",
    "    collection_path = base_collection_path + 'stage{0}'.format(stage) + '/CFHTLS_collection.pickle'\n",
    "    collection = swap.read_pickle(collection_path, 'collection')\n",
    "    for ID in collection.list():\n",
    "\n",
    "        subject = collection.member[ID]\n",
    "        catalog_i = []\n",
    "        \n",
    "        # for stage1 we shall skip the tests for now\n",
    "        if (stage == 1) * (subject.category == 'test'):\n",
    "            continue\n",
    "        \n",
    "        # flatten out x and y. also cut out empty entries\n",
    "        annotationhistory = subject.annotationhistory\n",
    "        x_unflat = annotationhistory['At_X']\n",
    "        x = np.array([xi for xj in x_unflat for xi in xj])\n",
    "\n",
    "        # cut out catalogs with no clicks\n",
    "        if len(x) < 1:\n",
    "            continue\n",
    "        # oh yeah there's that absolutely nutso entry with 50k clicks\n",
    "        if len(x) > 10000:\n",
    "            continue\n",
    "        \n",
    "        for category in categories:\n",
    "            if category == 'stage':\n",
    "                catalog_i.append(stage)\n",
    "            else:\n",
    "                catalog_i.append(subject.__dict__[category])\n",
    "        for category in annotation_categories:\n",
    "            catalog_i.append(list(annotationhistory[category]))\n",
    "            \n",
    "        catalog.append(catalog_i)\n",
    "catalog = pd.DataFrame(catalog, columns=categories + annotation_categories)\n",
    "\n",
    "# save catalog\n",
    "catalog.to_csv(annotated_catalog_path)\n",
    "\n",
    "# now repeat without annotations. Saves a lot of space!\n",
    "catalog[categories].to_csv(unannotated_catalog_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', array(['test', 'training'], dtype=object))\n",
      "('kind', array(['dud', 'sim', 'test'], dtype=object))\n",
      "('flavor', array(['dud', u'lensed galaxy', u'lensed quasar', u'lensing cluster',\n",
      "       'test'], dtype=object))\n",
      "('state', array(['active', 'inactive'], dtype=object))\n",
      "('status', array(['detected', 'rejected', 'undecided'], dtype=object))\n",
      "('truth', array(['LENS', 'NOT', 'UNKNOWN'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "check_types = ['category', 'kind', 'flavor', 'state', 'status', 'truth']\n",
    "for check_type in check_types:\n",
    "    print(check_type, np.unique(catalog[check_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For evaluating the objects in catalog, like the annotation_categories, you will want to use ast.literal_eval(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cluster Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "catalog = pd.read_csv(annotated_catalog_path)\n",
    "memory = joblib.Memory(cachedir=cachedir)\n",
    "# memory.clear()\n",
    "\n",
    "cluster_catalog = []\n",
    "ith = 0\n",
    "cluster_ID = 0\n",
    "# step through the objects in catalog\n",
    "for cati in range(len(catalog)):\n",
    "    \n",
    "    # get markers\n",
    "    x_unflat = literal_eval(catalog['At_X'][cati])\n",
    "    y_unflat = literal_eval(catalog['At_Y'][cati])\n",
    "    # flatten out x and y. also cut out empty entries\n",
    "    x = np.array([xi for xj in x_unflat for xi in xj])\n",
    "    y = np.array([yi for yj in y_unflat for yi in yj])\n",
    "    \n",
    "    # repeat for PD and PL = proxies for weight\n",
    "    PL_everyone = literal_eval(catalog['PL'][cati])\n",
    "    PL_unflat = []\n",
    "    PD_everyone = literal_eval(catalog['PD'][cati])\n",
    "    PD_unflat = []\n",
    "    for i, xj in enumerate(x_unflat):\n",
    "        # len(xj) of empty = 0\n",
    "        PL_unflat.append([PL_everyone[i]] * len(xj))\n",
    "        PD_unflat.append([PD_everyone[i]] * len(xj))\n",
    "\n",
    "    PL = np.array([PLi for PLj in PL_unflat for PLi in PLj])\n",
    "    PD = np.array([PDi for PDj in PD_unflat for PDi in PDj])\n",
    "    skill = expectedInformationGain(0.5, PL, PD)\n",
    "\n",
    "    # cluster\n",
    "    cluster_centers, cluster_center_labels, cluster_labels, n_clusters, dist_within = \\\n",
    "        outlier_clusters(x, y, skill, memory=memory, eps=eps, min_samples=min_samples)\n",
    "    \n",
    "    # add to catalog\n",
    "    for cluster_center_label_i, cluster_center_label in enumerate(cluster_center_labels):\n",
    "        \n",
    "        cluster_center = cluster_centers[cluster_center_label_i]\n",
    "        x, y = cluster_center\n",
    "\n",
    "        if np.int(np.ceil(x - stamp_size / 2)) >= 440:\n",
    "            print('Mislabled cluster? {0} {1} {2} {3}'.format(cati, cluster_center_label_i, x, y))\n",
    "            continue\n",
    "        elif np.int(np.ceil(y - stamp_size / 2)) >= 440:\n",
    "            print('Mislabled cluster? {0} {1} {2} {3}'.format(cati, cluster_center_label_i, x, y))\n",
    "            continue\n",
    "        elif np.int(np.floor(x + stamp_size / 2)) < 0:\n",
    "            print('Mislabled cluster? {0} {1} {2} {3}'.format(cati, cluster_center_label_i, x, y))\n",
    "            continue        \n",
    "        elif np.int(np.floor(y + stamp_size / 2)) < 0:\n",
    "            print('Mislabled cluster? {0} {1} {2} {3}'.format(cati, cluster_center_label_i, x, y))\n",
    "            continue\n",
    "        \n",
    "        if cluster_center_label == -1 or cluster_center_label > 100:\n",
    "            # outlier cluster\n",
    "            # so really every point is its own cluster...\n",
    "            D = 0\n",
    "        else:\n",
    "            D = dist_within[cluster_center_label]\n",
    "            \n",
    "        members = (cluster_labels == cluster_center_label)\n",
    "\n",
    "        N0 = np.sum(members)\n",
    "        S = np.sum(skill[members])\n",
    "            \n",
    "        # ['cluster_label', 'cluster_ID', 'x', 'y', 'num_markers', 'skill_sum', 'dist_within']\n",
    "        \n",
    "        fieldname = '{0}.png'.format(catalog['ZooID'][cati])\n",
    "        cutoutname = '{1}_{0}.png'.format(catalog['ZooID'][cati], cluster_ID)\n",
    "        cluster_catalog_i = [catalog[category][cati] for category in categories] + \\\n",
    "                            [cluster_center_label, cluster_ID, cluster_center[0], cluster_center[1], N0, S, D,\n",
    "                             cutoutname, fieldname]\n",
    "        cluster_catalog.append(cluster_catalog_i)\n",
    "        \n",
    "        cluster_ID += 1\n",
    "    \n",
    " \n",
    "cluster_catalog = pd.DataFrame(cluster_catalog, columns=categories + cluster_catalog_labels)\n",
    "\n",
    "\n",
    "# save catalog\n",
    "cluster_catalog.to_csv(cluster_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cutouts From Catalog\n",
    "\n",
    "add an 'in_alpha' parameter to cluster catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16314, 35083)\n"
     ]
    }
   ],
   "source": [
    "print (clusteri, len(cluster_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Seagate/cs231n/images/fields/ASW000526z.png\n"
     ]
    }
   ],
   "source": [
    "print(outname_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cluster_catalog = pd.read_csv(cluster_catalog_path)\n",
    "#alphas = []\n",
    "for clusteri in range(16314 , len(cluster_catalog)):\n",
    "\n",
    "    x = cluster_catalog['x'][clusteri]\n",
    "    y = cluster_catalog['y'][clusteri]\n",
    "    \n",
    "    outname_field = images_path + cluster_catalog['fieldname'][clusteri]\n",
    "    im = get_online_png(cluster_catalog['location'][clusteri], outname_field)       \n",
    "        \n",
    "    min_x = np.int(np.floor(x - stamp_size / 2))\n",
    "    max_x = np.int(np.ceil(x + stamp_size / 2))\n",
    "    min_y = np.int(np.floor(y - stamp_size / 2))\n",
    "    max_y = np.int(np.ceil(y + stamp_size / 2))\n",
    "    pad_min_x = 0\n",
    "    pad_max_x = 0\n",
    "    pad_min_y = 0\n",
    "    pad_max_y = 0\n",
    "    pad_trip = False\n",
    "    if min_x < 0:\n",
    "        pad_min_x = -min_x\n",
    "        min_x = 0\n",
    "        pad_trip = True\n",
    "    if max_x >= im.shape[1]:\n",
    "        pad_max_x = max_x - im.shape[1]\n",
    "        max_x = im.shape[1]\n",
    "        pad_trip = True\n",
    "    if min_y < 0:\n",
    "        pad_min_y = -min_y\n",
    "        min_y = 0\n",
    "        pad_trip = True\n",
    "    if max_y >= im.shape[0]:\n",
    "        pad_max_y = max_y - im.shape[0]\n",
    "        max_y = im.shape[0]\n",
    "        pad_trip = True\n",
    "    \n",
    "    im_cut = np.pad(im[min_y: max_y, min_x: max_x],\n",
    "                    ((pad_min_y, pad_max_y), (pad_min_x, pad_max_x), (0, 0)),\n",
    "                    mode='constant')\n",
    "    im_cut = im_cut[:stamp_size, :stamp_size, :3]\n",
    "    \n",
    "    # now check if the center is in a high alpha region (if alpha is included, as it is with training)\n",
    "    alpha = 0\n",
    "    if im.shape[2] == 4:\n",
    "        im_mask = im[:,:,3].copy()\n",
    "                \n",
    "        im_mask -= im_mask.mean()\n",
    "        im_mask /= im_mask.std()\n",
    "        im_mask[im_mask < 5] = 0\n",
    "        im_mask[im_mask >= 5] = 1\n",
    "        \n",
    "        if ((y >= 0) * (y < 440) *\n",
    "            (x >= 0) * (x < 440)):\n",
    "            if im_mask[y, x] == 1:\n",
    "                alpha = 1\n",
    "    alphas.append(alpha)\n",
    "    \n",
    "    outname_cluster = cutouts_path + cluster_catalog['cutoutname'][clusteri]\n",
    "    \n",
    "    imsave(outname_cluster, im_cut)\n",
    "    \n",
    "cluster_catalog['alpha'] = alphas\n",
    "# save catalog\n",
    "cluster_catalog.to_csv(cluster_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this took so long and I'm at 17 gb with something like 150k more clusters to go, let's stop and assess our distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'ID', u'ZooID', u'location', u'mean_probability', u'category', u'kind', u'flavor', u'state', u'status', u'truth', u'stage', u'cluster_label', u'cluster_ID', u'x', u'y', u'num_markers', u'skill_sum', u'dist_within', u'cutoutname', u'fieldname', u'alpha'], dtype='object')\n",
      "stage\n",
      "1        24177\n",
      "2        10906\n",
      "dtype: int64\n",
      "kind\n",
      "dud      9491\n",
      "sim     16562\n",
      "test     9030\n",
      "dtype: int64\n",
      "stage  kind\n",
      "1      dud      8362\n",
      "       sim     15815\n",
      "2      dud      1129\n",
      "       sim       747\n",
      "       test     9030\n",
      "dtype: int64\n",
      "flavor\n",
      "dud                9491\n",
      "lensed galaxy      5983\n",
      "lensed quasar      5271\n",
      "lensing cluster    5308\n",
      "test               9030\n",
      "dtype: int64\n",
      "stage  flavor         \n",
      "1      dud                8362\n",
      "       lensed galaxy      5286\n",
      "       lensed quasar      5271\n",
      "       lensing cluster    5258\n",
      "2      dud                1129\n",
      "       lensed galaxy       697\n",
      "       lensing cluster      50\n",
      "       test               9030\n",
      "dtype: int64\n",
      "stage  flavor           alpha\n",
      "1      dud              0        8362\n",
      "       lensed galaxy    0        3388\n",
      "                        1        1898\n",
      "       lensed quasar    0        3351\n",
      "                        1        1920\n",
      "       lensing cluster  0        3917\n",
      "                        1        1341\n",
      "2      dud              0        1129\n",
      "       lensed galaxy    0         551\n",
      "                        1         146\n",
      "       lensing cluster  0          45\n",
      "                        1           5\n",
      "       test             0        9030\n",
      "dtype: int64\n",
      "stage  flavor           status   \n",
      "1      dud              detected        6\n",
      "                        rejected     8124\n",
      "                        undecided     232\n",
      "       lensed galaxy    detected     4886\n",
      "                        rejected      202\n",
      "                        undecided     198\n",
      "       lensed quasar    detected     5098\n",
      "                        rejected       59\n",
      "                        undecided     114\n",
      "       lensing cluster  detected     4845\n",
      "                        rejected      240\n",
      "                        undecided     173\n",
      "2      dud              rejected      705\n",
      "                        undecided     424\n",
      "       lensed galaxy    detected      448\n",
      "                        rejected        3\n",
      "                        undecided     246\n",
      "       lensing cluster  detected       13\n",
      "                        undecided      37\n",
      "       test             detected      151\n",
      "                        rejected     2410\n",
      "                        undecided    6469\n",
      "dtype: int64\n",
      "stage  flavor         \n",
      "1      dud                0.001022\n",
      "       lensed galaxy      0.930656\n",
      "       lensed quasar      0.969760\n",
      "       lensing cluster    0.924871\n",
      "2      dud                0.020034\n",
      "       lensed galaxy      0.837553\n",
      "       lensing cluster    0.502393\n",
      "       test               0.163845\n",
      "Name: mean_probability, dtype: float64\n",
      "stage  flavor           status   \n",
      "1      dud              detected     9.995949e-01\n",
      "                        rejected     2.182681e-08\n",
      "                        undecided    1.099119e-02\n",
      "       lensed galaxy    detected     9.999509e-01\n",
      "                        rejected     2.858481e-08\n",
      "                        undecided    1.701469e-01\n",
      "       lensed quasar    detected     9.999514e-01\n",
      "                        rejected     2.562131e-08\n",
      "                        undecided    1.214938e-01\n",
      "       lensing cluster  detected     9.999110e-01\n",
      "                        rejected     2.887855e-08\n",
      "                        undecided    1.063787e-01\n",
      "2      dud              rejected     1.603194e-09\n",
      "                        undecided    5.334435e-02\n",
      "       lensed galaxy    detected     9.983332e-01\n",
      "                        rejected     5.608823e-18\n",
      "                        undecided    5.549653e-01\n",
      "       lensing cluster  detected     9.832626e-01\n",
      "                        undecided    3.334394e-01\n",
      "       test             detected     9.965689e-01\n",
      "                        rejected     3.190369e-09\n",
      "                        undecided    2.054472e-01\n",
      "Name: mean_probability, dtype: float64\n",
      "flavor           stage\n",
      "dud              1        8362\n",
      "                 2        1129\n",
      "lensed galaxy    1        5286\n",
      "                 2         697\n",
      "lensed quasar    1        5271\n",
      "lensing cluster  1        5258\n",
      "                 2          50\n",
      "test             2        9030\n",
      "dtype: int64\n",
      "alpha  flavor           stage\n",
      "0      dud              1        8362\n",
      "                        2        1129\n",
      "       lensed galaxy    1        3388\n",
      "                        2         551\n",
      "       lensed quasar    1        3351\n",
      "       lensing cluster  1        3917\n",
      "                        2          45\n",
      "       test             2        9030\n",
      "1      lensed galaxy    1        1898\n",
      "                        2         146\n",
      "       lensed quasar    1        1920\n",
      "       lensing cluster  1        1341\n",
      "                        2           5\n",
      "dtype: int64\n",
      "alpha  stage\n",
      "0      1        19018\n",
      "       2        10755\n",
      "1      1         5159\n",
      "       2          151\n",
      "dtype: int64\n",
      "alpha  flavor         \n",
      "0      dud                9491\n",
      "       lensed galaxy      3939\n",
      "       lensed quasar      3351\n",
      "       lensing cluster    3962\n",
      "       test               9030\n",
      "1      lensed galaxy      2044\n",
      "       lensed quasar      1920\n",
      "       lensing cluster    1346\n",
      "dtype: int64\n",
      "kind  stage\n",
      "dud   1         8362\n",
      "      2         1129\n",
      "sim   1        15815\n",
      "      2          747\n",
      "test  2         9030\n",
      "dtype: int64\n",
      "alpha  kind  stage\n",
      "0      dud   1         8362\n",
      "             2         1129\n",
      "       sim   1        10656\n",
      "             2          596\n",
      "       test  2         9030\n",
      "1      sim   1         5159\n",
      "             2          151\n",
      "dtype: int64\n",
      "alpha  stage\n",
      "0      1        19018\n",
      "       2        10755\n",
      "1      1         5159\n",
      "       2          151\n",
      "dtype: int64\n",
      "alpha  kind\n",
      "0      dud      9491\n",
      "       sim     11252\n",
      "       test     9030\n",
      "1      sim      5310\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# now let's print some essential stats:\n",
    "cc = cluster_catalog\n",
    "\n",
    "print(cc.columns)\n",
    "\n",
    "# get number of objects in stage 1 vs stage 2\n",
    "print(cc.groupby(['stage']).apply(len))\n",
    "\n",
    "print(cc.groupby(['kind']).apply(len))\n",
    "\n",
    "print(cc.groupby(['stage', 'kind']).apply(len))\n",
    "\n",
    "# get number of flavors\n",
    "print(cc.groupby(['flavor']).apply(len))\n",
    "\n",
    "\n",
    "# combine together\n",
    "print(cc.groupby(['stage', 'flavor']).apply(len))\n",
    "print(cc.groupby(['stage', 'flavor', 'alpha']).apply(len))\n",
    "print(cc.groupby(['stage', 'flavor', 'status']).apply(len))\n",
    "\n",
    "# also show median probability\n",
    "print(cc.groupby(['stage', 'flavor'])['mean_probability'].apply(np.mean))\n",
    "print(cc.groupby(['stage', 'flavor', 'status'])['mean_probability'].apply(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the cutouts:\n",
      "stage  alpha  flavor         \n",
      "1      0      dud                8362\n",
      "              lensed galaxy      3388\n",
      "              lensed quasar      3351\n",
      "              lensing cluster    3917\n",
      "       1      lensed galaxy      1898\n",
      "              lensed quasar      1920\n",
      "              lensing cluster    1341\n",
      "2      0      dud                1129\n",
      "              lensed galaxy       551\n",
      "              lensing cluster      45\n",
      "              test               9030\n",
      "       1      lensed galaxy       146\n",
      "              lensing cluster       5\n",
      "dtype: int64\n",
      "stage  alpha  kind\n",
      "1      0      dud      8362\n",
      "              sim     10656\n",
      "       1      sim      5159\n",
      "2      0      dud      1129\n",
      "              sim       596\n",
      "              test     9030\n",
      "       1      sim       151\n",
      "dtype: int64\n",
      "Statistics for the fields:\n",
      "stage  flavor         \n",
      "1      dud                2971\n",
      "       lensed galaxy      1879\n",
      "       lensed quasar      1930\n",
      "       lensing cluster    1901\n",
      "2      dud                 201\n",
      "       lensed galaxy       144\n",
      "       lensing cluster       8\n",
      "       test               3413\n",
      "dtype: int64\n",
      "stage  kind\n",
      "1      dud     2971\n",
      "       sim     5710\n",
      "2      dud      201\n",
      "       sim      152\n",
      "       test    3413\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cluster_catalog = pd.read_csv('/Users/cpd/Projects/strongcnn/catalog/cluster_catalog.csv')\n",
    "print('Statistics for the cutouts:')\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'flavor']).apply(len))\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'kind']).apply(len))\n",
    "\n",
    "# the fields are where the cutouts come from so let's get some stats from them, too\n",
    "field_catalog = pd.read_csv('/Users/cpd/Projects/strongcnn/catalog/unannotated_catalog.csv')\n",
    "print('Statistics for the fields:')\n",
    "print(field_catalog.groupby(['stage', 'flavor']).apply(len))\n",
    "print(field_catalog.groupby(['stage', 'kind']).apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's examine the properties of number of markers per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "stage  alpha  flavor         \n",
      "1      0      dud                  3.395719\n",
      "              lensed galaxy        3.561098\n",
      "              lensed quasar        3.888093\n",
      "              lensing cluster     19.882563\n",
      "       1      lensed galaxy       78.094310\n",
      "              lensed quasar      113.298438\n",
      "              lensing cluster    115.826249\n",
      "2      0      dud                  5.346324\n",
      "              lensed galaxy        1.740472\n",
      "              lensing cluster     41.111111\n",
      "              test                 4.293355\n",
      "       1      lensed galaxy       95.123288\n",
      "              lensing cluster    307.000000\n",
      "Name: num_markers, dtype: float64\n",
      "stage  alpha  kind\n",
      "1      0      dud       3.395719\n",
      "              sim       9.663476\n",
      "       1      sim     101.003877\n",
      "2      0      dud       5.346324\n",
      "              sim       4.713087\n",
      "              test      4.293355\n",
      "       1      sim     102.139073\n",
      "Name: num_markers, dtype: float64\n",
      "Median\n",
      "stage  alpha  flavor         \n",
      "1      0      dud                 1\n",
      "              lensed galaxy       1\n",
      "              lensed quasar       1\n",
      "              lensing cluster     1\n",
      "       1      lensed galaxy      56\n",
      "              lensed quasar      84\n",
      "              lensing cluster    82\n",
      "2      0      dud                 1\n",
      "              lensed galaxy       1\n",
      "              lensing cluster     1\n",
      "              test                1\n",
      "       1      lensed galaxy      96\n",
      "              lensing cluster    43\n",
      "Name: num_markers, dtype: float64\n",
      "stage  alpha  kind\n",
      "1      0      dud      1\n",
      "              sim      1\n",
      "       1      sim     71\n",
      "2      0      dud      1\n",
      "              sim      1\n",
      "              test     1\n",
      "       1      sim     96\n",
      "Name: num_markers, dtype: float64\n",
      "MAD\n",
      "stage  alpha  flavor         \n",
      "1      0      dud                 0.0\n",
      "              lensed galaxy       0.0\n",
      "              lensed quasar       0.0\n",
      "              lensing cluster     0.0\n",
      "       1      lensed galaxy      31.0\n",
      "              lensed quasar      45.0\n",
      "              lensing cluster    45.0\n",
      "2      0      dud                 0.0\n",
      "              lensed galaxy       0.0\n",
      "              lensing cluster     0.0\n",
      "              test                0.0\n",
      "       1      lensed galaxy      29.5\n",
      "              lensing cluster    27.0\n",
      "Name: num_markers, dtype: float64\n",
      "stage  alpha  kind\n",
      "1      0      dud      0\n",
      "              sim      0\n",
      "       1      sim     39\n",
      "2      0      dud      0\n",
      "              sim      0\n",
      "              test     0\n",
      "       1      sim     31\n",
      "Name: num_markers, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def MAD(x):\n",
    "    med = np.median(x, axis=0)\n",
    "    return np.median(np.abs(x - med), axis=0)\n",
    "\n",
    "print('Mean')\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'flavor']).aggregate(np.mean)['num_markers'])\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'kind']).aggregate(np.mean)['num_markers'])\n",
    "\n",
    "print('Median')\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'flavor']).aggregate(np.median)['num_markers'])\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'kind']).aggregate(np.median)['num_markers'])\n",
    "\n",
    "print('MAD')\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'flavor']).aggregate(MAD)['num_markers'])\n",
    "print(cluster_catalog.groupby(['stage', 'alpha', 'kind']).aggregate(MAD)['num_markers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's examine the number of clusters and the number of markers on a field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of Fields\n",
      "ZooID\n",
      "ASW0000015    8\n",
      "ASW000001u    4\n",
      "ASW0000028    5\n",
      "ASW000002n    2\n",
      "ASW000003x    3\n",
      "ASW000005h    3\n",
      "ASW000005m    9\n",
      "ASW000006r    2\n",
      "ASW000009e    3\n",
      "ASW00000ah    5\n",
      "ASW00000ak    9\n",
      "ASW00000bw    9\n",
      "ASW00000bx    2\n",
      "ASW00000ch    2\n",
      "ASW00000dw    8\n",
      "...\n",
      "ASW0009djr     4\n",
      "ASW0009djs     6\n",
      "ASW0009djt     4\n",
      "ASW0009dju     5\n",
      "ASW0009djv     5\n",
      "ASW0009djw    10\n",
      "ASW0009djx     4\n",
      "ASW0009djy     3\n",
      "ASW0009djz     6\n",
      "ASW0009dk0     3\n",
      "ASW0009dk1     4\n",
      "ASW0009dk2     6\n",
      "ASW0009dk3     6\n",
      "ASW0009dk4     5\n",
      "ASW0009dk5     7\n",
      "Length: 12290, dtype: int64\n",
      "Median number clusters\n",
      "stage  flavor         \n",
      "1      dud                2.0\n",
      "       lensed galaxy      2.0\n",
      "       lensed quasar      2.0\n",
      "       lensing cluster    2.0\n",
      "2      dud                5.0\n",
      "       lensed galaxy      7.0\n",
      "       lensing cluster    8.5\n",
      "       test               2.0\n",
      "Name: num_clusters, dtype: float64\n",
      "stage  kind\n",
      "1      dud     2\n",
      "       sim     2\n",
      "2      dud     5\n",
      "       sim     7\n",
      "       test    2\n",
      "Name: num_clusters, dtype: float64\n",
      "Mean number clusters\n",
      "stage  flavor         \n",
      "1      dud                2.824958\n",
      "       lensed galaxy      3.184141\n",
      "       lensed quasar      2.731088\n",
      "       lensing cluster    2.785376\n",
      "2      dud                5.626866\n",
      "       lensed galaxy      7.520833\n",
      "       lensing cluster    9.000000\n",
      "       test               2.645766\n",
      "Name: num_clusters, dtype: float64\n",
      "stage  kind\n",
      "1      dud     2.824958\n",
      "       sim     2.898249\n",
      "2      dud     5.626866\n",
      "       sim     7.598684\n",
      "       test    2.645766\n",
      "Name: num_clusters, dtype: float64\n",
      "Median number markers\n",
      "stage  flavor         \n",
      "1      dud                  3\n",
      "       lensed galaxy       64\n",
      "       lensed quasar       88\n",
      "       lensing cluster     86\n",
      "2      dud                 28\n",
      "       lensed galaxy      179\n",
      "       lensing cluster    219\n",
      "       test                10\n",
      "Name: num_markers, dtype: float64\n",
      "stage  kind\n",
      "1      dud       3.0\n",
      "       sim      79.0\n",
      "2      dud      28.0\n",
      "       sim     180.5\n",
      "       test     10.0\n",
      "Name: num_markers, dtype: float64\n",
      "Mean number markers\n",
      "stage  flavor         \n",
      "1      dud                  9.635076\n",
      "       lensed galaxy       93.206493\n",
      "       lensed quasar      119.462176\n",
      "       lensing cluster    122.853761\n",
      "2      dud                 58.726368\n",
      "       lensed galaxy      194.597222\n",
      "       lensing cluster    520.125000\n",
      "       test                11.359215\n",
      "Name: num_markers, dtype: float64\n",
      "stage  kind\n",
      "1      dud       9.635076\n",
      "       sim     111.951313\n",
      "2      dud      58.726368\n",
      "       sim     211.730263\n",
      "       test     11.359215\n",
      "Name: num_markers, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cluster_catalog = pd.read_csv('/Users/cpd/Projects/strongcnn/catalog/cluster_catalog.csv')\n",
    "field_catalog = pd.read_csv('/Users/cpd/Projects/strongcnn/catalog/unannotated_catalog.csv')\n",
    "\n",
    "print('Median number of Fields')\n",
    "print(cluster_catalog.groupby(['ZooID']).apply(len))\n",
    "zooids = field_catalog['ZooID']\n",
    "field_catalog = field_catalog.set_index('ZooID')\n",
    "field_catalog['num_clusters'] = cluster_catalog.groupby(['ZooID']).apply(len)\n",
    "field_catalog['num_markers'] = cluster_catalog.groupby(['ZooID']).aggregate(np.sum)['num_markers']\n",
    "field_catalog = field_catalog.set_index('Unnamed: 0')\n",
    "\n",
    "print('Median number clusters')\n",
    "print(field_catalog.groupby(['stage', 'flavor']).aggregate(np.median)['num_clusters'])\n",
    "print(field_catalog.groupby(['stage', 'kind']).aggregate(np.median)['num_clusters'])\n",
    "\n",
    "print('Mean number clusters')\n",
    "print(field_catalog.groupby(['stage', 'flavor']).aggregate(np.mean)['num_clusters'])\n",
    "print(field_catalog.groupby(['stage', 'kind']).aggregate(np.mean)['num_clusters'])\n",
    "\n",
    "print('Median number markers')\n",
    "print(field_catalog.groupby(['stage', 'flavor']).aggregate(np.median)['num_markers'])\n",
    "print(field_catalog.groupby(['stage', 'kind']).aggregate(np.median)['num_markers'])\n",
    "\n",
    "print('Mean number markers')\n",
    "print(field_catalog.groupby(['stage', 'flavor']).aggregate(np.mean)['num_markers'])\n",
    "print(field_catalog.groupby(['stage', 'kind']).aggregate(np.mean)['num_markers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'ID', u'ZooID', u'location', u'mean_probability', u'category', u'kind', u'flavor', u'state', u'status', u'truth', u'stage', u'At_X', u'At_Y', u'PD', u'PL'], dtype='object')\n",
      "stage\n",
      "1        8681\n",
      "2        3766\n",
      "dtype: int64\n",
      "kind\n",
      "dud     3172\n",
      "sim     5862\n",
      "test    3413\n",
      "dtype: int64\n",
      "stage  kind\n",
      "1      dud     2971\n",
      "       sim     5710\n",
      "2      dud      201\n",
      "       sim      152\n",
      "       test    3413\n",
      "dtype: int64\n",
      "flavor\n",
      "dud                3172\n",
      "lensed galaxy      2023\n",
      "lensed quasar      1930\n",
      "lensing cluster    1909\n",
      "test               3413\n",
      "dtype: int64\n",
      "stage  flavor         \n",
      "1      dud                2971\n",
      "       lensed galaxy      1879\n",
      "       lensed quasar      1930\n",
      "       lensing cluster    1901\n",
      "2      dud                 201\n",
      "       lensed galaxy       144\n",
      "       lensing cluster       8\n",
      "       test               3413\n",
      "dtype: int64\n",
      "stage  flavor           status   \n",
      "1      dud              detected        4\n",
      "                        rejected     2887\n",
      "                        undecided      80\n",
      "       lensed galaxy    detected     1735\n",
      "                        rejected       65\n",
      "                        undecided      79\n",
      "       lensed quasar    detected     1871\n",
      "                        rejected       20\n",
      "                        undecided      39\n",
      "       lensing cluster  detected     1769\n",
      "                        rejected       77\n",
      "                        undecided      55\n",
      "2      dud              rejected      127\n",
      "                        undecided      74\n",
      "       lensed galaxy    detected       94\n",
      "                        rejected        1\n",
      "                        undecided      49\n",
      "       lensing cluster  detected        2\n",
      "                        undecided       6\n",
      "       test             detected       59\n",
      "                        rejected      957\n",
      "                        undecided    2397\n",
      "dtype: int64\n",
      "stage  flavor         \n",
      "1      dud                0.001632\n",
      "       lensed galaxy      0.929710\n",
      "       lensed quasar      0.972904\n",
      "       lensing cluster    0.933985\n",
      "2      dud                0.018590\n",
      "       lensed galaxy      0.842285\n",
      "       lensing cluster    0.477581\n",
      "       test               0.161975\n",
      "Name: mean_probability, dtype: float64\n",
      "stage  flavor           status   \n",
      "1      dud              detected     9.993977e-01\n",
      "                        rejected     2.182251e-08\n",
      "                        undecided    1.062773e-02\n",
      "       lensed galaxy    detected     9.999307e-01\n",
      "                        rejected     2.984655e-08\n",
      "                        undecided    1.524675e-01\n",
      "       lensed quasar    detected     9.999232e-01\n",
      "                        rejected     2.730196e-08\n",
      "                        undecided    1.756091e-01\n",
      "       lensing cluster  detected     9.999054e-01\n",
      "                        rejected     2.619193e-08\n",
      "                        undecided    1.213332e-01\n",
      "2      dud              rejected     1.277257e-09\n",
      "                        undecided    5.049312e-02\n",
      "       lensed galaxy    detected     9.983128e-01\n",
      "                        rejected     5.608823e-18\n",
      "                        undecided    5.601545e-01\n",
      "       lensing cluster  detected     9.810140e-01\n",
      "                        undecided    3.097695e-01\n",
      "       test             detected     9.953070e-01\n",
      "                        rejected     3.002540e-09\n",
      "                        undecided    2.061315e-01\n",
      "Name: mean_probability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# repeat for the regular catalog (by field) instead of clusters\n",
    "cc_all = catalog\n",
    "cc = cc_all\n",
    "\n",
    "# now let's print some essential stats:\n",
    "\n",
    "\n",
    "print(cc.columns)\n",
    "\n",
    "# get number of objects in stage 1 vs stage 2\n",
    "print(cc.groupby(['stage']).apply(len))\n",
    "\n",
    "print(cc.groupby(['kind']).apply(len))\n",
    "\n",
    "print(cc.groupby(['stage', 'kind']).apply(len))\n",
    "\n",
    "# get number of flavors\n",
    "print(cc.groupby(['flavor']).apply(len))\n",
    "\n",
    "\n",
    "# combine together\n",
    "print(cc.groupby(['alpha']).apply(len))\n",
    "print(cc.groupby(['alpha', 'stage']).apply(len))\n",
    "print(cc.groupby(['alpha', 'stage', 'flavor']).apply(len))\n",
    "\n",
    "print(cc.groupby(['stage', 'flavor']).apply(len))\n",
    "print(cc.groupby(['stage', 'flavor', 'status']).apply(len))\n",
    "\n",
    "# also show median probability\n",
    "print(cc.groupby(['stage', 'flavor'])['mean_probability'].apply(np.mean))\n",
    "print(cc.groupby(['stage', 'flavor', 'status'])['mean_probability'].apply(np.mean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So in sum:\n",
    "\n",
    "We have something like 6700 simulated lenses, 3700 known duds, 104408 'tests' (of which we can probably safely use 93000 as duds from the stage 1 rejected tests).\n",
    "\n",
    "Data augmentation for these are clearly needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with knownlenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what entries in our catalog are in the knownlens ones?\n",
    "kl = pd.read_csv(knownlens_path)\n",
    "cc = pd.read_csv(cluster_catalog_path)\n",
    "\n",
    "cc = cc.set_index(['ZooID'])\n",
    "cc_kl = []\n",
    "klifail = []\n",
    "for kli in range(len(kl)):\n",
    "    kx = kl['x'][kli]\n",
    "    ky = 440 - kl['y'][kli]\n",
    "    if kl['ZooID'][kli] in cc.index:\n",
    "        cci = cc.loc[kl['ZooID'][kli]]\n",
    "        ccx = cci['x']\n",
    "        ccy = cci['y']\n",
    "        \n",
    "        l2 = np.sqrt(np.square(kx - ccx) + np.square(ky - ccy))\n",
    "        if type(l2) != np.float64:\n",
    "            cmin = cci.iloc[np.argmin(l2.values)]\n",
    "        else:\n",
    "            cc_kl.append(cci)\n",
    "    else:\n",
    "        klifail.append(kli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the data: Take the images, apply a reasonable affine transformation\n",
    "\n",
    "One guy actually did this in the convnet for the galaxy zoo morphologies -- we don't have to necessarily store 32x of these data if we don't want (also helps combat overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
